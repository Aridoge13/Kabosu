{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da8e072",
   "metadata": {},
   "source": [
    "Code Sample: Scalable Data Preprocessing Pipeline for Machine Learning\n",
    "\n",
    "Context: This Python script demonstrates a robust preprocessing workflow for biological data, preparing high-dimensional datasets (e.g., from transcriptomics or metabolomics) for machine learning analysis. It highlights key skills in data validation, feature engineering, and ensuring reproducibilityâ€”directly applicable to processing large-scale omics datasets.\n",
    "\n",
    "Link: https://github.com/Aridoge13/Kabosu/blob/main/src/jupyter_notebooks/preprocess.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d8d22",
   "metadata": {},
   "source": [
    "Cell 1: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(input(\"path to data:\"))\n",
    "labels = pd.read_csv(input(\"path to labels:\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f3f47f",
   "metadata": {},
   "source": [
    "Cell 2:  Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4743e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data\n",
    "assert len(data) == len(labels), \"Mismatched samples!\"\n",
    "assert \"sample_id\" in data.columns, \"sample_id column missing!\"\n",
    "assert \"disease_status\" in labels.columns, \"disease_status column missing!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d236d6",
   "metadata": {},
   "source": [
    "Cell 3: Labelling data and check class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8cdb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data.drop(columns=[\"sample_id\"])\n",
    "y = labels[\"disease_status\"]\n",
    "\n",
    "# Encode categorical labels\n",
    "if y.dtype == \"object\":\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    joblib.dump(le, \"models/label_encoder.pkl\")\n",
    "\n",
    "# Check class balance\n",
    "logging.info(f\"Class distribution:\\n{pd.Series(y).value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde5129",
   "metadata": {},
   "source": [
    "Cell 4: Scaling, feature selection and saving preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1370ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(f_classif, k=100)\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "X_test = selector.transform(X_test)\n",
    "joblib.dump(selector, \"models/feature_selector.pkl\")\n",
    "\n",
    "logging.info(\n",
    "    f\"Final shapes - X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "logging.info(\n",
    "    f\"Final shapes - y_train: {y_train.shape}, y_test: {y_test.shape}\")\n",
    "# Save preprocessed data\n",
    "pd.DataFrame(X_train).to_csv(\"data/X_train.csv\", index=False)\n",
    "pd.DataFrame(X_test).to_csv(\"data/X_test.csv\", index=False)\n",
    "pd.DataFrame(y_train).to_csv(\"data/y_train.csv\", index=False)\n",
    "pd.DataFrame(y_test).to_csv(\"data/y_test.csv\", index=False)\n",
    "logging.info(\"Preprocessing completed successfully!\")\n",
    "# Save the preprocessed data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
